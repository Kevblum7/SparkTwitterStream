{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb492070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import tweepy\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "consumer_key = \"Ax79DI6gXdMjOCQyQ61v2Khbj\"\n",
    "consumer_secret = \"DBSmfUL50FlhpVnePa373lOpBFffJjrGInXbSGG4T7Ze2RRQTl\"\n",
    "access_token = \"1418173405988376579-9g3SF5klnWOgd62nUfTfaqrQdzkJRA\"\n",
    "access_token_secret = \"q3jO28xbGDlvE6djCNeoSMQbtkosZYT7mBTv0O6wznMpw\"\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cb0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('classifier').config(\"spark.driver.memory\",\"16g\").config(\"spark.executor.memoryOverhead\",\"1000M\").getOrCreate()\n",
    "df = spark.read.load(\"trainingandtestdata/training.1600000.processed.noemoticon.csv\",format=\"csv\", sep=\",\")\n",
    "df=df.toDF('polarity','tweet_id','tweet_date','query_string','tweet_screen_name','Tweet')\n",
    "df2=spark.read.load(\"trainingandtestdata/testdata.manual.2009.06.14.csv\",format=\"csv\", sep=\",\")\n",
    "df2=df2.toDF('polarity','tweet_id','tweet_date','query_string','tweet_screen_name','Tweet')\n",
    "#df.show(5)\n",
    "#df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03752022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[['tweet_id','query_string','Tweet','polarity']]\n",
    "#df2=df2[['tweet_id','query_string','Tweet','polarity']]\n",
    "#df.groupBy('polarity').count().orderBy('count',ascending=False).show(10,False)\n",
    "#df=df.toPandas()\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175350c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.wordnet import *\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pyspark.sql.types import StringType,DoubleType,IntegerType\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "worddict = set(nltk.corpus.words.words())\n",
    "\n",
    "def preprocessing(text):\n",
    "    wordset_n = set(wn.lemmatize(w, NOUN) for w in word_tokenize(text.lower().strip()))\n",
    "    wordset_v = set(wn.lemmatize(w, VERB) for w in wordset_n)\n",
    "    wordset = set(wn.lemmatize(w, ADJ) for w in wordset_v)\n",
    "    wordset = wordset & worddict\n",
    "    return ' '.join(list(wordset))\n",
    "tem=df.union(df2)\n",
    "#tem.show()\n",
    "brand_udf=udf(preprocessing,StringType())\n",
    "tem=tem.withColumn('text',brand_udf(tem['Tweet']))\n",
    "#df=df.withColumn('text',brand_udf(df['Tweet']))\n",
    "#df2=df2.withColumn('text',brand_udf(df2['Tweet']))\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca4f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tem = tokenizer.transform(tem)\n",
    "#df=tokenizer.transform(df)\n",
    "#df2=tokenizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6414ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "count = CountVectorizer (inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "model = count.fit(tem)\n",
    "tem = model.transform(tem)\n",
    "#tem.show()\n",
    "#model1=count.fit(df)\n",
    "#df=model1.transform(df)\n",
    "#model2=count.fit(df2)\n",
    "#df2=model2.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56d75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(tem)\n",
    "tem = idfModel.transform(tem)\n",
    "tem = tem.withColumn('polarity', tem['polarity'].cast(IntegerType()))\n",
    "#idfModel = idf.fit(df)\n",
    "#df = idfModel.transform(df)\n",
    "#df = df.withColumn('polarity', df['polarity'].cast(IntegerType()))\n",
    "#idfModel = idf.fit(df2)\n",
    "#df2 = idfModel.transform(df2)\n",
    "#df2 = df2.withColumn('polarity', df2['polarity'].cast(IntegerType()))\n",
    "trainingDF,testDF = tem.randomSplit([0.7, 0.3],seed=20)\n",
    "trainingDF=trainingDF.repartition(10)\n",
    "testDF=testDF.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef88294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf_classifier=RandomForestClassifier(labelCol='polarity',numTrees=200).fit(trainingDF.select(['text','words','rawFeatures','features','polarity']))\n",
    "rf_predictions=rf_classifier.transform(testDF.select(['text','words','rawFeatures','features','polarity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7db99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|polarity|prediction|\n",
      "+--------+----------+\n",
      "|       0|       4.0|\n",
      "|       0|       4.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       4.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rf_predictions.select(['polarity','prediction']).show(10)\n",
    "rf_predictions.select(['polarity','prediction']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1de0369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.284024\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "testDF=testDF.toPandas()\n",
    "rf_predictions=rf_predictions.toPandas()\n",
    "testDF['prediction']=rf_predictions['prediction']\n",
    "testDF=testDF[['tweet_id','query_string','tweet_screen_name','tweet_date','Tweet','text','polarity','prediction']]\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ba41a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1a09205c400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "mycol = mydb[\"tweet\"]\n",
    "records = json.loads(testDF.T.to_json()).values()\n",
    "mydb.mycol.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d8945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b2ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CS644)",
   "language": "python",
   "name": "pycharm-9bc77049"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
