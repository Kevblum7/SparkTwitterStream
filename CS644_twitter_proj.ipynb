{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb492070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "consumer_key = \"Ax79DI6gXdMjOCQyQ61v2Khbj\"\n",
    "consumer_secret = \"DBSmfUL50FlhpVnePa373lOpBFffJjrGInXbSGG4T7Ze2RRQTl\"\n",
    "access_token = \"1418173405988376579-9g3SF5klnWOgd62nUfTfaqrQdzkJRA\"\n",
    "access_token_secret = \"q3jO28xbGDlvE6djCNeoSMQbtkosZYT7mBTv0O6wznMpw\"\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cb0692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+------------+-----------------+--------------------+\n",
      "|polarity|  tweet_id|          tweet_date|query_string|tweet_screen_name|               Tweet|\n",
      "+--------+----------+--------------------+------------+-----------------+--------------------+\n",
      "|       0|1467810369|Mon Apr 06 22:19:...|    NO_QUERY|  _TheSpecialOne_|@switchfoot http:...|\n",
      "|       0|1467810672|Mon Apr 06 22:19:...|    NO_QUERY|    scotthamilton|is upset that he ...|\n",
      "|       0|1467810917|Mon Apr 06 22:19:...|    NO_QUERY|         mattycus|@Kenichan I dived...|\n",
      "|       0|1467811184|Mon Apr 06 22:19:...|    NO_QUERY|          ElleCTF|my whole body fee...|\n",
      "|       0|1467811193|Mon Apr 06 22:19:...|    NO_QUERY|           Karoli|@nationwideclass ...|\n",
      "+--------+----------+--------------------+------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------+--------------------+------------+-----------------+--------------------+\n",
      "|polarity|tweet_id|          tweet_date|query_string|tweet_screen_name|               Tweet|\n",
      "+--------+--------+--------------------+------------+-----------------+--------------------+\n",
      "|       4|       3|Mon May 11 03:17:...|     kindle2|           tpryan|@stellargirl I lo...|\n",
      "|       4|       4|Mon May 11 03:18:...|     kindle2|           vcu451|Reading my kindle...|\n",
      "|       4|       5|Mon May 11 03:18:...|     kindle2|           chadfu|Ok, first assesme...|\n",
      "|       4|       6|Mon May 11 03:19:...|     kindle2|            SIX15|@kenburbary You'l...|\n",
      "|       4|       7|Mon May 11 03:21:...|     kindle2|         yamarama|@mikefish  Fair e...|\n",
      "+--------+--------+--------------------+------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master('local').appName('classifier').getOrCreate()\n",
    "df = spark.read.csv(\"trainingandtestdata/training.1600000.processed.noemoticon.csv\")\n",
    "df=df.toDF('polarity','tweet_id','tweet_date','query_string','tweet_screen_name','Tweet')\n",
    "df2=spark.read.csv(\"trainingandtestdata/testdata.manual.2009.06.14.csv\")\n",
    "df2=df2.toDF('polarity','tweet_id','tweet_date','query_string','tweet_screen_name','Tweet')\n",
    "df.show(5)\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03752022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|polarity|count |\n",
      "+--------+------+\n",
      "|0       |800000|\n",
      "|4       |800000|\n",
      "+--------+------+\n",
      "\n",
      "+--------+-----+\n",
      "|polarity|count|\n",
      "+--------+-----+\n",
      "|4       |182  |\n",
      "|0       |177  |\n",
      "|2       |139  |\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df[['tweet_id','query_string','Tweet','polarity']]\n",
    "df2=df2[['tweet_id','query_string','Tweet','polarity']]\n",
    "df.groupBy('polarity').count().orderBy('count',ascending=False).show(10,False)\n",
    "df2.groupBy('polarity').count().orderBy('count',ascending=False).show(10,False)\n",
    "#df=df.toPandas()\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175350c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+--------+--------------------+---------+\n",
      "|  tweet_id|query_string|               Tweet|polarity|                text|clean_len|\n",
      "+----------+------------+--------------------+--------+--------------------+---------+\n",
      "|1467810369|    NO_QUERY|@switchfoot http:...|       0|get day that thir...|       50|\n",
      "|1467810672|    NO_QUERY|is upset that he ...|       0|result cry school...|       82|\n",
      "|1467810917|    NO_QUERY|@Kenichan I dived...|       0|out ball save go ...|       64|\n",
      "|1467811184|    NO_QUERY|my whole body fee...|       0|whole feel my bod...|       44|\n",
      "|1467811193|    NO_QUERY|@nationwideclass ...|       0|at mad no all i c...|       71|\n",
      "|1467811372|    NO_QUERY|@Kwesidei not the...|       0|  the crew whole not|       18|\n",
      "|1467811592|    NO_QUERY|         Need a hug |       0|          a hug need|       10|\n",
      "|1467811594|    NO_QUERY|@LOLTrish hey  lo...|       0|fine only i how r...|       62|\n",
      "|1467811795|    NO_QUERY|@Tatiana_K nope t...|       0|they do nope it have|       20|\n",
      "|1467812025|    NO_QUERY|@twittera que me ...|       0|                  me|        2|\n",
      "|1467812416|    NO_QUERY|spring break in p...|       0|break snow plain ...|       34|\n",
      "|1467812579|    NO_QUERY|I just re-pierced...|       0|       i just my ear|       13|\n",
      "|1467812723|    NO_QUERY|@caregiving I cou...|       0|wa think loss i t...|       56|\n",
      "|1467812771|    NO_QUERY|@octolinz16 It it...|       0|i talk to you do ...|       45|\n",
      "|1467812784|    NO_QUERY|@smarrison i woul...|       0|really i would ju...|       65|\n",
      "|1467812799|    NO_QUERY|@iamjazzyfizzle I...|       0|miss get wa i how...|       60|\n",
      "|1467812964|    NO_QUERY|Hollis' death sce...|       0|out death will cu...|       82|\n",
      "|1467813137|    NO_QUERY|about to file taxes |       0|   tax about to file|       17|\n",
      "|1467813579|    NO_QUERY|@LettyA ahh ive a...|       0|rent to always th...|       32|\n",
      "|1467813782|    NO_QUERY|@FakerPattyPattz ...|       0|out drink you be ...|       44|\n",
      "+----------+------------+--------------------+--------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader.wordnet import *\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pyspark.sql.types import StringType,DoubleType,IntegerType\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "worddict = set(nltk.corpus.words.words())\n",
    "\n",
    "def preprocessing(text):\n",
    "    wordset_n = set(wn.lemmatize(w, NOUN) for w in word_tokenize(text.lower().strip()))\n",
    "    wordset_v = set(wn.lemmatize(w, VERB) for w in wordset_n)\n",
    "    wordset = set(wn.lemmatize(w, ADJ) for w in wordset_v)\n",
    "    wordset = wordset & worddict\n",
    "    return ' '.join(list(wordset))\n",
    "brand_udf=udf(preprocessing,StringType())\n",
    "df=df.withColumn('text',brand_udf(df['Tweet']))\n",
    "df=df.withColumn('clean_len',F.length('text'))\n",
    "df2=df2.withColumn('text',brand_udf(df2['Tweet']))\n",
    "df2=df2.withColumn('clean_len',F.length('text'))\n",
    "tem=df.union(df2)\n",
    "tem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca4f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tem = tokenizer.transform(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6414ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+--------+--------------------+---------+--------------------+--------------------+\n",
      "|  tweet_id|query_string|               Tweet|polarity|                text|clean_len|               words|         rawFeatures|\n",
      "+----------+------------+--------------------+--------+--------------------+---------+--------------------+--------------------+\n",
      "|1467810369|    NO_QUERY|@switchfoot http:...|       0|get day that thir...|       50|[get, day, that, ...|(29209,[2,4,5,8,1...|\n",
      "|1467810672|    NO_QUERY|is upset that he ...|       0|result cry school...|       82|[result, cry, sch...|(29209,[1,4,5,7,1...|\n",
      "|1467810917|    NO_QUERY|@Kenichan I dived...|       0|out ball save go ...|       64|[out, ball, save,...|(29209,[0,2,3,10,...|\n",
      "|1467811184|    NO_QUERY|my whole body fee...|       0|whole feel my bod...|       44|[whole, feel, my,...|(29209,[5,6,7,15,...|\n",
      "|1467811193|    NO_QUERY|@nationwideclass ...|       0|at mad no all i c...|       71|[at, mad, no, all...|(29209,[0,1,5,8,2...|\n",
      "|1467811372|    NO_QUERY|@Kwesidei not the...|       0|  the crew whole not|       18|[the, crew, whole...|(29209,[3,24,383,...|\n",
      "|1467811592|    NO_QUERY|         Need a hug |       0|          a hug need|       10|      [a, hug, need]|(29209,[4,66,432]...|\n",
      "|1467811594|    NO_QUERY|@LOLTrish hey  lo...|       0|fine only i how r...|       62|[fine, only, i, h...|(29209,[0,4,8,35,...|\n",
      "|1467811795|    NO_QUERY|@Tatiana_K nope t...|       0|they do nope it have|       20|[they, do, nope, ...|(29209,[5,9,12,72...|\n",
      "|1467812025|    NO_QUERY|@twittera que me ...|       0|                  me|        2|                [me]|  (29209,[18],[1.0])|\n",
      "|1467812416|    NO_QUERY|spring break in p...|       0|break snow plain ...|       34|[break, snow, pla...|(29209,[5,11,205,...|\n",
      "|1467812579|    NO_QUERY|I just re-pierced...|       0|       i just my ear|       13|  [i, just, my, ear]|(29209,[0,6,21,81...|\n",
      "|1467812723|    NO_QUERY|@caregiving I cou...|       0|wa think loss i t...|       56|[wa, think, loss,...|(29209,[0,2,3,5,7...|\n",
      "|1467812771|    NO_QUERY|@octolinz16 It it...|       0|i talk to you do ...|       45|[i, talk, to, you...|(29209,[0,2,5,8,1...|\n",
      "|1467812784|    NO_QUERY|@smarrison i woul...|       0|really i would ju...|       65|[really, i, would...|(29209,[0,1,3,4,9...|\n",
      "|1467812799|    NO_QUERY|@iamjazzyfizzle I...|       0|miss get wa i how...|       60|[miss, get, wa, i...|(29209,[0,2,3,5,7...|\n",
      "|1467812964|    NO_QUERY|Hollis' death sce...|       0|out death will cu...|       82|[out, death, will...|(29209,[1,2,15,18...|\n",
      "|1467813137|    NO_QUERY|about to file taxes |       0|   tax about to file|       17|[tax, about, to, ...|(29209,[2,56,1110...|\n",
      "|1467813579|    NO_QUERY|@LettyA ahh ive a...|       0|rent to always th...|       32|[rent, to, always...|(29209,[2,3,36,48...|\n",
      "|1467813782|    NO_QUERY|@FakerPattyPattz ...|       0|out drink you be ...|       44|[out, drink, you,...|(29209,[1,3,8,13,...|\n",
      "+----------+------------+--------------------+--------+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "count = CountVectorizer (inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "model = count.fit(tem)\n",
    "tem = model.transform(tem)\n",
    "tem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56d75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(tem)\n",
    "tem = idfModel.transform(tem)\n",
    "tem = tem.withColumn('polarity', tem['polarity'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef88294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = tem.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2a5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6c4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow every follower of the authenticated user\n",
    "timeline = api.home_timeline()\n",
    "data = pd.DataFrame(data=[tweet.text for tweet in timeline], columns=['Tweet'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CS644)",
   "language": "python",
   "name": "pycharm-9bc77049"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
