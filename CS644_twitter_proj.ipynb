{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb492070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import tweepy\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "#consumer_key = \"Ax79DI6gXdMjOCQyQ61v2Khbj\"\n",
    "#consumer_secret = \"DBSmfUL50FlhpVnePa373lOpBFffJjrGInXbSGG4T7Ze2RRQTl\"\n",
    "#access_token = \"1418173405988376579-9g3SF5klnWOgd62nUfTfaqrQdzkJRA\"\n",
    "#access_token_secret = \"q3jO28xbGDlvE6djCNeoSMQbtkosZYT7mBTv0O6wznMpw\"\n",
    "# Creating the authentication object\n",
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "#api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cb0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open 2 command prompts\n",
    "#terminal 1\n",
    "#cd %SPARK_HOME%\n",
    "#bin\\spark-class2.cmd org.apache.spark.deploy.master.Master\n",
    "#open in browser localhost:8080\n",
    "#terminal 2\n",
    "#cd %SPARK_HOME%\n",
    "#bin\\spark-class2.cmd org.apache.spark.deploy.worker.Worker -c 4 -m 32G spark://192.168.1.227:7077\n",
    "#open in browser localhost:8081\n",
    "spark = SparkSession.builder.master('spark://192.168.1.227:7077').appName('classifier').config('spark.executor.memory', '32g').getOrCreate()\n",
    "df = spark.read.options(delimiter=\",\",header=False).csv(\"trainingandtestdata/training.1600000.processed.noemoticon.csv\")\n",
    "df=df.toDF('polarity','tweet_id','tweet_date','query_string','tweet_screen_name','Tweet')\n",
    "df2=spark.read.options(delimiter=\",\",header=False).csv(\"trainingandtestdata/testdata.manual.2009.06.14.csv\")\n",
    "df2=df2.toDF('polarity','tweet_id','tweet_date','query_string','tweet_screen_name','Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175350c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "def preprocessing(text):\n",
    "    # process the tweets\n",
    "\n",
    "    #Convert to lower case\n",
    "    tweet = text.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+',' ',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet\n",
    "tem=df.union(df2)\n",
    "brand_udf=udf(preprocessing,StringType())\n",
    "tem=tem.withColumn('text',brand_udf(tem['Tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac14afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "tem1=tem.select('tweet_id','Tweet','text','polarity')\n",
    "tem1 = tem1.withColumn('polarity', tem1['polarity'].cast(IntegerType()))\n",
    "(trainingData, testData) = tem1.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50126d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"rawFeatures\")\n",
    "idf = IDF(minDocFreq=2, inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(labelCol='polarity')\n",
    "\n",
    "# Pipeline Architecture\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, lr])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc10fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)\n",
    "predictions1=predictions.toPandas()\n",
    "# Select example rows to display.\n",
    "#predictions.select(\"text\", \"polarity\", \"prediction\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1de0369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752789071140396\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "testData=testData.toPandas()\n",
    "predictions=predictions1\n",
    "testData['prediction']=predictions['prediction']\n",
    "testData=testData[['tweet_id','Tweet','polarity','prediction']]\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ba41a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1dd52e5bd40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "mycol = mydb[\"tweet\"]\n",
    "records = json.loads(testData.T.to_json()).values()\n",
    "mydb.mycol.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e615767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.appName(\"Twitter Streaming App\").getOrCreate()\n",
    "tweet_df = spark.readStream.format(\"socket\").option(\"host\", \"127.0.0.1\").option(\"port\", 5556).load()\n",
    "tweet_df_string = tweet_df.selectExpr(\"CAST(value AS STRING)\")\n",
    "tweet_df_string = tweet_df_string.withColumnRenamed(\"value\" , \"tweet\")\n",
    "writeTweet = tweet_df_string.writeStream.format(\"csv\").option(\"format\" , \"append\").option(\"path\", \"C:/Users/Sajin.LAPTOP-RE0DL8PH/Sajin/Shajee_Fall_2021/CS644/temp\").option(\"checkpointLocation\" , \"checkpoints\").queryName(\"tweetquery\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d32bb64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\CS644\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CS644\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CS644\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Tweet'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAJIN~1.LAP\\AppData\\Local\\Temp/ipykernel_11140/552480467.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CS644\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CS644\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Tweet'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(60) \n",
    "writeTweet.stop()\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/Users/Sajin.LAPTOP-RE0DL8PH/Sajin/Shajee_Fall_2021/CS644/temp\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "dataframe = pd.DataFrame()\n",
    "for i in all_filenames:\n",
    "    if (os.stat(f\"C:/Users/Sajin.LAPTOP-RE0DL8PH/Sajin/Shajee_Fall_2021/CS644/temp/{i}\").st_size != 0):\n",
    "        try:\n",
    "            d = pd.read_csv(f\"C:/Users/Sajin.LAPTOP-RE0DL8PH/Sajin/Shajee_Fall_2021/CS644/temp/{i}\" , engine=\"python\")\n",
    "            dt = d.T\n",
    "            dt = dt.reset_index()\n",
    "            dataframe = dataframe.append(dt)\n",
    "        except:\n",
    "            pass\n",
    "dataframe = dataframe.rename(columns={\"index\" : \"Tweet\"})\n",
    "dataframe = dataframe.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "dataframe = dataframe.reset_index(drop=True)\n",
    "dataframe = dataframe[dataframe['Tweet'] != \"\"]\n",
    "dataframe = dataframe[dataframe['Tweet'] != \".\"]\n",
    "dataframe = dataframe[dataframe['Tweet'] != None]\n",
    "\n",
    "dataframe = dataframe.reset_index(drop=True)\n",
    "range1 = range(100, 100 + dataframe['Tweet'].size  )\n",
    "list1 = list(range1)\n",
    "dfg = pd.DataFrame(list1 , columns = ['tweet_id'])\n",
    "dfg = dfg['tweet_id'].astype('str')\n",
    "list_polarity =[]\n",
    "for b in range(dataframe['Tweet'].size):\n",
    "    list_polarity.append(0)\n",
    "    \n",
    "dfp = pd.DataFrame(list_polarity , columns = ['polarity'])\n",
    "dataframe = dataframe.join(dfg)\n",
    "dataframe = dataframe.join(dfp)\n",
    "sparkDF = spark.createDataFrame(dataframe)\n",
    "sparkDF=sparkDF[['tweet_id','Tweet','polarity']]\n",
    "brand_udf=udf(preprocessing,StringType())\n",
    "sparkDF=sparkDF.withColumn('text',brand_udf(sparkDF['Tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.transform(sparkDF)\n",
    "pred2=pred.toPandas()\n",
    "spark.stop()\n",
    "pred2=pred2[['tweet_id','Tweet','prediction']]\n",
    "mycol2 = mydb[\"tweet2\"]\n",
    "records2 = json.loads(pred2.T.to_json()).values()\n",
    "mydb.mycol.insert_many(records2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc911bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CS644)",
   "language": "python",
   "name": "pycharm-9bc77049"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
